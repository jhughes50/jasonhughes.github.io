<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>
		Jason Hughes Research
	</title>
	<style>
		p {
    		padding: 10px;
    		border: 5px solid rgb(175, 225, 175);
    		background-color: white;
		}
		
		 /* h3 {
			color:rgb(175, 225, 175);;
			padding: 40px;
			border: 5px solid rgb(175, 225, 175);
			background-color: white;
			
		}  */
		img {
			border:5px solid rgb(175, 225, 175)
		}
		a {
			color:rgb(175, 225, 175);
		}
	</style>
</head>
<body style="background-color: black;" link="#000" alink="#017bf5" vlink="#000">
	<br />
	
	<h3 align="center">
	
		<font face="Courier New" size="5">
			<a href="index.html">Home</a>&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="CV_JasonHughes_5_2021.pdf">CV</a>&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="research.html">Research</a>&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="pubs.html">Publications</a>&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="https://github.com/jhughes50">Github</a>
		</font>
	</h3>
	<br><br><br>
	<h1 align="center">
		<font face="Courier New" color="#AFE1AF" size="7">
			3. Robotics Research Center at West Point
		</font>
	</h1>
	<p style="margin:0px 200px 200px">
		<font face="Lato" size="4">	
			I am currently a robotics research fellow at the Robotics Resarch Center at the United States Military Academy at West Point, funded
			under the Army Research Labs Journeyman Fellowship. I work on government funded research projects, individual projects for publication and 
			advise undergraduates on their research projects. I specialize in unmanned ariel systems and their applications. <br>
			Some of the government funded projects I work on involve the deveoplement of autonomous flight methods for specific applications. I also contribute to West Point's efforts in the <a href="https://www.dcist.org/">DCIST</a> project.<br>
			I'm currenlty developing a deep learning model for the predict the position of a quadcopter when GPS and VIO are  not viable options.<br>
			I advise the computer vision team where we look at solving complicated object detection problems.
	<h1 align="center">
		<font face="Courier New" color="#AFE1AF" size="7">
			2. Dr. Juntao Chen Research Group
		</font>
	</h1>
	<br>
	<h1 align="center"><img src="images/network.png" alt="net" style="width:300px;height:300px;">
	<img src="images/deceptive.png" style="width:300px;height:300px;"> </h1>
	<p style="margin:0px 200px 200px">
		<font face="Lato" size="4">	
As a graduate student I conducted research in the Juntao Chen Research Group in Fordham University's Computer and Information Science Department. In this group we first applied a fairness metric to distributed discrete optimal transport for so a more fair resource Allocation scheme could be computed. 
We then constructed a discrete distriubted OT algorithm that considers the possibility that nodes could be compromised and misrepresent their constraints to the other nodes in the network. 
Next, we incorporated differential privacy into the distributed OT paradigm. Since nodes broadcast their information to other nodes, that could be used to trace back sensitive data. Finally, we considered 
developed an algorithm for the security investment problem from multiple sources to multiple targets. I also advised undergraduateson the application of 
distibuted OT to secuirty investment applications. Finally, we considered the application of a fair and optimal allocation of covid-19 vaccine.
		</font>
	</p>
	<h1 align="center">
		<font face="Courier New" color="#AFE1AF" size="7">
			1. Fordham University Robotics and Computer Vision Lab
		</font>
	</h1>
	<h1 align="center">
	<img src="images/drone.jpg" alt="drone" style="width:300px;height:300px;" > &nbsp;&nbsp;&nbsp;&nbsp;
	<img src="images/drone_angles.png" alt="angles" style="width:300px;height:300px;" > 
	</h1>
	<p style="margin:30px 200px">
		<font face="Lato" size="4">
		
I started out working in the Robotics and Computer Vision lab as a research assistant helping a master's student with his work on drone to drone wind detection. We gathered IMU data from one drone flying underneath another. The data from the drone underneath as well as control data was then fed the data to a classification program to see if the computer could predict when a drone was overhead after it trained on the data. <br>
I took over as the lead researcher on the next portion of the project, looking at if data gathered from the drone's IMU when it is flying near walls could be used to predict the presence of a wall in a flight path. To do this we gathered data from the drone when it was flying with a wall to its left, right and front. Then I built a classifier and feature generator for the computer to train and test on with the data. <br>
We found that when using a RandomForest classifier, we can accurately predict which side a wall is on in relation to the drone with above 90% accuracy. This means this could be a potential replacement for more power-hungry radar and camera sensors when building autonomous drones. 
		</font>
	</p>
</body>
</html>
